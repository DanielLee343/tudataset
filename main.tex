%%%%%%%% ICML 2020 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}



\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage{booktabs}
\usepackage{url}
\usepackage{todonotes}
\usepackage{multirow}
\usepackage{tikz}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{thmtools}		
\usepackage{mleftright}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{remark}[theorem]{Remark}

\usepackage{thm-restate}
\usepackage[mathic=true]{mathtools}
\usepackage{fixmath}
\usepackage{siunitx}

\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{enumitem}
\setlist[enumerate]{noitemsep, topsep=0.5\topsep}
\setlist[description]{noitemsep, topsep=0.5\topsep}
\setlist[itemize]{noitemsep, topsep=0.5\topsep}

\usepackage{enumitem}
\setlist[enumerate]{noitemsep, topsep=0.5\topsep}
\setlist[description]{noitemsep, topsep=0.5\topsep}
\setlist[itemize]{noitemsep, topsep=0.5\topsep}

\usepackage{setspace}
\usepackage[protrusion=true,expansion=false, activate={true,nocompatibility},final,kerning=true,spacing=true]{microtype}

\usepackage{ellipsis}
\usepackage{xspace}
\usepackage{hfoldsty}

\usepackage{ifthen}
\newcommand{\CC}[1][]{$\text{C\hspace{-.25ex}}^{_{_{_{++}}}}
	\ifthenelse{\equal{#1}{}}{}{\text{\hspace{-.625ex}#1}}$}

\newcommand{\win}[1]{$\hspace{-0.3mm}$\textbf{#1}}
\newcommand{\sd}[1]{\scriptsize{$\pm$#1}}


% Let cleveref and thmtools work together
\makeatletter
\def\thmt@refnamewithcomma #1#2#3,#4,#5\@nil{%
	\@xa\def\csname\thmt@envname #1utorefname\endcsname{#3}%
	\ifcsname #2refname\endcsname
	\csname #2refname\expandafter\endcsname\expandafter{\thmt@envname}{#3}{#4}%
	\fi
}
\makeatother
\usepackage[capitalise,noabbrev]{cleveref}   

\newcommand{\new}[1]{\emph{#1}}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\newcommand{\cA}{\ensuremath{{\mathcal A}}\xspace}
\newcommand{\cB}{\ensuremath{{\mathcal B}}\xspace}
\newcommand{\cC}{\ensuremath{{\mathcal C}}\xspace}
\newcommand{\cD}{\ensuremath{{\mathcal D}}\xspace}
\newcommand{\cF}{\ensuremath{{\mathcal F}}\xspace}
\newcommand{\cH}{\ensuremath{{\mathcal H}}\xspace}
\newcommand{\cN}{\ensuremath{{\mathcal N}}\xspace}
\newcommand{\cO}{\ensuremath{{\mathcal O}}\xspace}
\newcommand{\cP}{\ensuremath{{\mathcal P}}\xspace}
\newcommand{\cR}{\ensuremath{{\mathcal R}}\xspace}
\newcommand{\cS}{\ensuremath{{\mathcal S}}\xspace}
\newcommand{\cU}{\ensuremath{{\mathcal U}}\xspace}
\newcommand{\cV}{\ensuremath{{\mathcal V}}\xspace}
\newcommand{\cPn}{\ensuremath{{\mathcal P}_n}\xspace}

\newcommand{\fA}{\ensuremath{\mathfrak{A}}\xspace}
\newcommand{\fB}{\ensuremath{\mathfrak{B}}\xspace}
\newcommand{\fC}{\ensuremath{\mathfrak{C}}\xspace}

\newcommand{\fa}{\ensuremath{\mathfrak{a}}\xspace}
\newcommand{\fb}{\ensuremath{\mathfrak{b}}\xspace}
\newcommand{\fc}{\ensuremath{\mathfrak{c}}\xspace}
\newcommand{\fd}{\ensuremath{\mathfrak{d}}\xspace}

\newcommand{\bA}{\ensuremath{{\bf A}}\xspace}
\newcommand{\bB}{\ensuremath{{\bf B}}\xspace}
\newcommand{\bK}{\ensuremath{{\bf K}}\xspace}
\newcommand{\bE}{\ensuremath{{\bf E}}\xspace}
\newcommand{\bN}{\ensuremath{{\bf N}}\xspace}
\newcommand{\bG}{\ensuremath{{\bf G}}\xspace}

\newcommand{\ba}{\ensuremath{{\bf a}}\xspace}
\newcommand{\bb}{\ensuremath{{\bf b}}\xspace}
\newcommand{\bc}{\ensuremath{{\bf c}}\xspace}

\newcommand{\bbE}{\ensuremath{\mathbb{E}}}
\newcommand{\bbR}{\ensuremath{\mathbb{R}}}
\newcommand{\bbQ}{\ensuremath{\mathbb{Q}}}
\newcommand{\bbP}{\ensuremath{\mathbb{P}}}
\newcommand{\bbZ}{\ensuremath{\mathbb{Z}}}
\newcommand{\bbN}{\ensuremath{\mathbb{N}}}
\newcommand{\bbNn}{\ensuremath{\mathbb{N}_0}}

\newcommand{\bbRnp}{\ensuremath{\bbR_{\geq 0}}}
\newcommand{\bbQnp}{\ensuremath{\bbQ_{\geq}}}
\newcommand{\bbZnp}{\ensuremath{\bbZ_{\geq}}}

\newcommand{\bbRsp}{\ensuremath{\bbR_>}}
\newcommand{\bbQsp}{\ensuremath{\bbQ_>}}
\newcommand{\bbZsp}{\ensuremath{\bbZ_>}}

\newcommand{\cp}{\textsf{P}\xspace}
\newcommand{\cnp}{\textsf{NP}\xspace}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\GG}{\mathbb{G}}
\newcommand{\GN}{\mathbb{G}_n}
\newcommand{\rb}{\right\}\xspace}
\newcommand{\lb}{\left\{\xspace}
\newcommand{\lbr}{\left(\xspace} 
\newcommand{\rbr}{\right)\xspace}
\newcommand{\ndelta}{\ensuremath{\overline{\delta}}}
\newcommand{\oms}{\{\!\!\{}
\newcommand{\cms}{\}\!\!\}}
\newcommand{\trans}{^T}
\renewcommand{\vec}[1]{\mathbf{#1}}

\newcommand{\nk}[1]{{{\textcolor{brown}{\textbf{[NK:} {#1}\textbf{]}}}}}

\usepackage{ifthen}
\newcommand{\CPP}[1][]{$\text{C\hspace{-.25ex}}^{_{_{_{++}}}}
	\ifthenelse{\equal{#1}{}}{}{\text{\hspace{-.625ex}#1}}$}

\usepackage{icml2020}





\icmltitlerunning{TUD Datasets}

\begin{document}

\twocolumn[
\icmltitle{TUD Datasets: A collection of benchmark datasets for learning with graphs}
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{C. Morris}{p}
\icmlauthor{N.\,M.\,Kriege}{vie}
\icmlauthor{K. Kersting}{darm}
\icmlauthor{P. Mutzw}{bonn}
\icmlauthor{N. Neumann}{wustl}
\end{icmlauthorlist}

\icmlaffiliation{p}{CERC in Data Science for Real-Time Decision-Making, Polytechnique Montr√©al}
\icmlaffiliation{vie}{University of Vienna}
\icmlaffiliation{darm}{Machine Learning Group, TU Darmstadt}
\icmlaffiliation{bonn}{Department of Computer Science, University of Bonn}
\icmlaffiliation{wustl}{Washington University in St. Louis}
\icmlcorrespondingauthor{Christopher Morris}{christopher.morris@tu-dortmund.de}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Recently, there has been an increasing interest in learning with graph data, especially using graph neural networks.  However, the development of meaningful benchmark datasets and standardized evaluation procedures is lagging behind. That is, most paper papers evaluate their methods on small-scale datasets leading to high standard deviations and hard to interpret results, consequently hindering advancements in this area. To address this, we introduce the \textsc{Tud dataset} for graph classification and regression. The dataset consists of over 150 \nk{Zur Zeit sind es 128. Mehr als 100 klingt auch gut oder?} datasets from a wide range of applications and varying sizes. We provide Python-based data loaders, baseline implementations, and evaluation tools. Here, we give an overview of the datasets, evaluation tools, and provide baseline experiments. 
\nk{Make clear that these are datasets collected from the authors of various papers}
\end{abstract}

\section{Introduction}

Graph-structured data is ubiquitous across application domains ranging from chemo- and bioinformatics to image and social network analysis. To develop successful machine learning models in these domains, we need techniques that can exploit the rich information inherent in the graph structure, as well as the feature information contained within nodes and edges. In recent years, numerous approaches have been proposed for machine learning with graphs---most notably, approaches based on graph \new{kernels}~\cite{Kri+2019} or using \new{graph neural networks} (GNNs)~\cite{Gil+2017}. However, most papers, even recent ones, evaluate newly proposed architectures or methods on a fixed set of small-scale benchmark datasets leading to high standard deviations and hard to interpret results. 

Here, we give an overview of \textsc{Tud datasets}. The benchmark collection consists of over 150 datasets from a wide range of domains for supervised learning with graphs, i.e., classificiation and regression. All datasets are provided in a common dataset format at \url{graphlearning.io}, and can easily be accessed from popular graph learning frameworks such as \emph{Pytorch Geometric}~\cite{Fey+2019} and \emph{DGL}~\cite{Wan+2019}.

\paragraph{Related work.}

There exists two approaches to supervised learing with graphs, graph kernels and graph neural networks (GNNs). Graph kernels have been studied extensively in the past 15 years, see ~\cite{Kri+2019} for a thorough overview. 
Important approaches include random-walk and shortest paths based kernels~\cite{Gaertner2003,Sugiyama2015,Bor+2005,Kri+2017b}, as well as the Weisfeiler-Lehman subtree kernel~\cite{She+2011,Mor+2017}. 
Further recent works focus on assignment-based approaches~\cite{Kri+2016,Nik+2017}, spectral approaches~\cite{Kon+2016}, and graph decomposition approaches~\cite{Nik+2018}.

Recently, GNNs~\cite{Gil+2017} emerged as a alternative to graph kernels. Notable instances of this model include~\cite{Duv+2015},~\cite{Li+2016},~\cite{Ham+2017} and the spectral approaches proposed in~\cite{Bru+2014,Def+2015,Kip+2017}---all of which descend from early work in~\cite{Kir+1995,Mer+2005,Sca+2009}. A unifying message passing architecture can be found in~\cite{Gil+2017}. Two recent surveys~\cite{wu2019comprehensive,zhou2018graph} provide a thorough overview of graph neural networks

The papers~\cite{Fey+2019,Err+2019,Dwi+2020} evalute GNNs using a unified evaluation procedure, however, both only use small scale datasets. Recently, \url{ogb.stanford.edu} launchend, however the provided datasets for graph classification focus on chemistry applications, and the number is quite limited at this point.



\paragraph{Contributions} We give an overview of \textsc{Tud dataset}, its unified evalution procudures, and baseline methods. Moreover, we report results on a experimental study comparing graph kernels and GNNs on a subset of the \textsc{Tud dataset}.

\section{The TUD dataset collection}

The \textsc{Tud dataset} contain over 150 datasets provided at \url{graphlearning.io}. The data loader, baseline methods, experimental evaluation tool can be installed by running \texttt{pip install tud-datasets}, see \url{XXX} for further details.

\subsection{Datasets}

Our collection of datasets covers graphs from various domains, which were provided by different authors. Therefore, they differ regarding the used graph model even within the same domain and the provided annotations, e.g., discrete or continuous node/edge attributes. We give an overview of some representative domains and graph models.

\paragraph{Small molecules.} 
A commonly used class of graph datasets are derived from small molecules with class labels representing, e.g., toxicity or biological activity determined in the context of drug discovery. A molecule is represented by a graph in which nodes take the places of atoms and edges that of chemical bonds. Consequently, the labels indicate atom and bond types, where additional chemical attributes are possible. The graph models differs, e.g., in whether hydrogen atoms represented explicitly by nodes and bonds in aromatic rings are annotated accordingly.
Our collection contains small datasets commonly used in the early graph kernel literature such as \textsc{Mutag}~\citep{Deb+1991} and \textsc{Ptc}~\cite{Helma2001}, medium-sized datasets, e.g., \textsc{Nci1} and \textsc{Nci109}~\citep{Wal+2008,She+2011}, as well as several large datasets derived from the \emph{Tox21 Challenge 2014} or \emph{PubChem}~\citep{Kim2018}. This includes the 11 datasets from anticancer screen tests with different cancer cell lines used by \citet{Yan2008} to demonstrate the efficacy of classifiers based on significant graph patterns. These datasets, the largest of which contain more than 79k graphs, are typically not balanced and contain far more small molecules that are identified as inactive against cancer cells.
The \textsc{Alchemy} was proposed by~\citet{Chen2019a} for benchmarking {AI} models.

For some cheminformatics prediction tasks, the geometrical arrangement of atoms has been determined and should be taken into account in a rotation-invariant manner. In order to achieve this, complete graphs with edges annotated by distances are commonly used~\citep{Kri+2012,Gil+2017}. Our collection contains the four datasets \textsc{Bzr}, \textsc{Cox2}, \textsc{Dhfr}, \textsc{Er} initially published by \citet{Sut+2003} in two versions, with 3d coordinates of atoms and inter-atom distances, respectively, cf.~\citep{Mah+2006,Kri+2012}.

\paragraph{Bioinformatics.}
The datasets \textsc{DD}, \textsc{Enzymes} and \textsc{Proteins} represent macromolecules. \citet{Bor+2005a} introduced a graph model for proteins, where nodes represent secondary structure elements and are annotated by their type, i.e., helix, sheet or turn, as well as several physical and chemical information. Two nodes are connected by an edge if they are neighbors along the amino acid sequence or one of three nearest neighbors in space. Using this approach, the dataset \textsc{Enzymes} was derived from the BRENDA database~\citep{Schomburg2004}. Here, the task is to assign enzymes to one of the 6 EC top level classes, which reflect the chemical reaction they catalyze. Similarly, the dataset \textsc{Proteins} was derived from \citep{Dob+2003} and comes with the task to predict whether a protein is an enzyme. The dataset \textsc{DD} used by \citet{She+2011} is based on the same data, but contains graphs, where nodes represent individual amino acids and edges their spatial proximity.


\paragraph{Computer vision.}
Graph-based methods are widely used in computer vision for various tasks using diverse graph models. Our collection provides several datasets originating from the \emph{IAM Graph Database}~\citep{Riesen2008} such as \textsc{Letter} and \textsc{Fingerprint}. Other datasets represent \textsc{Cuneiform} signs~\citep{Kriege2018}, 3d point clouds for robot grasping tasks (\textsc{FirstMM\_DB}) and semantic image processing (\textsc{Msrc})~\citep{Neu+2016}.

\paragraph{Social networks.}
\citet{Yan+2015a} introduced several graph classification datasets derived from social networks. In the \textsc{Reddit} datasets each graph represents a discussion thread, where nodes correspond to users, two of which are connected by an edge, if one responded to a comment of the other. This graph model is used to derive several datasets, where the classification task is to distinguish either discussion-based and question/answer-based subreddits (\textsc{Reddit-Binary}) or predict the subreddit, where the thread was posted (\textsc{Reddit-Multi-5K} and \textsc{Reddit-Multi-12K}). \textsc{Collab} is dataset derived from scientific collaboration networks. Each graph is the ego-network of a researcher and the task is to predict his research field, i.e., High Energy, Condensed Matter or Astro Physics. Similarly, the \textsc{Imdb} datasets consist of ego-networks derived from actor collaborations and the task is to predict the genre, e.g.,  Action vs.\@ Romance.
Similar approaches were used by~\citet{Rozemberczki2020} to obtain larger social network datasets. \textsc{Reddit\_Threads} contains more than 200k graphs with the task to predict whether a thread is discussion based. \textsc{Deezer\_Ego\_Nets} and \textsc{Twitch\_Egos} contain ego-networks derived from online services and the task is to predict the gender and play beahavior (single or multiple games) of the central user.
\textsc{GitHub\_Stargazers} contains graphs representing the social networks of GitHub users divided into those who starred popular machine learning and web development repositories.


Recently, temporal graphs were considered by \citet{Oettershagen2019}, where edges represent the contact or interaction between two individuals at a certain point in time. These graphs are of interest when studying dissemination processes such as the spreading of epidemics, rumours or fake news. We provide temporal graph classification datasets derived from \textsc{Tumblr}~\citep{rozenshtein2016reconstructing}, \textsc{Dblp} and \textsc{Facebook}~\citep{viswanath2009evolution} as well as contacts between students at the \textsc{MIT}~\cite{konect:eagle06}, in a \textsc{Highschool} and visitors at the \textsc{Infectious} exhibition~\citep{Isella2011}.

\paragraph{Synthetic.}
Several graph datasets contain synthetic instances that where typically generated to demonstrate the strengths or weaknesses of specific methods. The datasets \textsc{SyntheticNew} and \textsc{SyntheticNew} were created by \citet{Fer+2013} (see Erratum) and \citet{Mor+2016}, respectively, to demonstrate the ability of kernels to operate on graphs with continuous attributes.
With the same goal, the dataset \textsc{Frankenstein} was obtained from a small molecule dataset by replacing the atom labels by MNIST digit images~\citep{Ors+2015}

\citet{Knyazev2019} introduced the datasets \textsc{Colors} and \textsc{Triangles}, where the task is to count the number of nodes with a given one-hot-encoded color and the number of triangles, respectively. These classification tasks were considered particularly challenging for graph neural networks.

\subsection{Baselines}

In order to provide meaningful baselines, we provide implementation of common graph kernels was well as GNNs baselines. We have implemented the \new{Weisfeiler-Lehman Subtree}~\cite{She+2011}, \new{Shortest-path}~\cite{Bor+2005}, \new{Graphlet}~\cite{She+2009} \nk{Das ist eine Variante mit Labeln und 3 Knoten oder?}, \new{Weisfeiler-Lehman Optimal Assigment}~\cite{Kri+2016} kernel, as well as the higher-order WL kernels~\cite{Mor+2019b}, in \CPP and made them accessable through the Python interface of \textsc{Tud dataset}, see \url{XXX} for further details.  Moreover, all GNN architectures implemented in PyTorch Geometric can be used as baseline as well. 

Vertex kernel and edge kernel? \nk{W√§re interessant!}


\subsection{Evaluation tools}\label{eval}

In order to insure a fair and meaningful comparision between methods, we propose the following evaluation proceudres, and software tools for kernels and GNN approaches. All proposed methods can be conviently accessed from the Python interface, see \url{XXX} for further details. First, for kernels we propose the established $C$-SVM implementation \textsc{LibSvm}~\cite{Cha+11} for kernels that compute a Gram matrix, and the linear $C$-SVM implementation \textsc{LibLinear}~\cite{Fan+2008} for kernels  that can be computed based on explicit feature maps. We optimize GNNs end-to-end using \textsc{Adam}~\cite{}. Too compute accuracies and other metrics for evaluation, we propose to use $10$-fold cross validation, where we select a validation set uniformly at random from each training fold ($10\%$ of the training fold), to select hyperparamets, e.g., number of iterations, $C$ parameter, number of layers, learning rate, feature dimension, etc.  


Repeat ten times?



\section{Experimental evaluation}

Our intention here is to provide baseline experiments, and compare graph kernels and GNNs. More precisely, we address the following questions:
\begin{description}
	\item[Q1] Are GNNs superior to graph kernels? Is there a single method that dominates?
	\item[Q2] ?
	\item[Q3] ?
\end{description}

\subsection{Experimental protocol}

We used the following datasets, graph kernels, and GNN baselines.

\paragraph{Datasets.} We used the \textsc{deezer\_ego\_nets}, \textsc{github\_stargazers}, \textsc{Enymes},
\textsc{Imdb-BINARY}, \textsc{Imdb-MULTI}, \textsc{Mcf-7}, \textsc{Molt-4},	\textsc{Nci1}, \textsc{Proteins},
\textsc{Reddit-Binary},	\textsc{reddit\_threads}, \textsc{twitch\_egos}, \textsc{Uacc257}. See the appendix for dataset statistics.

\paragraph{Graph kernels.} As kernel baselines we used the \new{Weisfeiler-Lehman Subtree}~\cite{She+2011}, \new{Shortest-path}~\cite{Bor+2005}, \new{Graphket}~\cite{She+2009}, \new{Weisfeiler-Lehman Optimal Assigment} \textsc{WL-OA}~\cite{Kri+2016}, and $\delta$-$2$-LWL$^+$ kernel~\cite{Mor+2019b} included in the \textsc{TUD Dataset} package. The $C$-parameter was selected from $\{10^{-3}, 10^{-2}, \dotsc, 10^{2},$ $10^{3}\}$ from the validation set. For the larger datasets, we computed sparse feature vectors for each graph and used the linear $C$-SVM implementation of \text{Liblinear}~\cite{Fan+2008}. The number of iterations of the \textsc{$1$-WL}, \textsc{WL-OA}, and the  $\delta$-$2$-LWL$^+$ were selected from $\{0,\dotsc,5\}$.\footnote{As already shown in~\cite{She+2011}, choosing the number of iterations too large will lead to overfitting.}

\paragraph{GNNs.} We used the GNN architectures \textsc{GCN}~\cite{Kip+2017}, \textsc{Sage}~\cite{Ham+2017}, \textsc{Gin} and \textsc{Gin-$\varepsilon$}~\cite{Xu+2018b} as neural baselines. For all experiments, we used the global mean operator to obtain graph-level outputs. For each dataset, we optimize the number of hidden units from $
\{16, 32, 64, 128\}$, the number of layers from $ \{2, 3, 4, 5\}$ and the learning rate from $ \{0.0001, 0.001, 0.01 \}$ with respect to the validation set. The batch size was fixed to $128$.

For both methods, we used the evaluation procecude described in~\cref{eval} to optimize hyperparameters and compute accuracies. All experiments can be reproduced using the scripts provided at \url{XXX}.

\subsection{Results and discussion}
See~\cref{t2l}.





\begin{table*}[t]\centering		
	\caption{Classification accuracies in percent and standard deviations,  \textsc{OOT}--- Computation did not finish within one day, \textsc{OOM}--- Out of memory.}
	\label{t2l}	
	\resizebox{0.8\textwidth}{!}{ 	\renewcommand{\arraystretch}{1.1}
		\begin{tabular}{@{}c <{\enspace}@{}lccccccc@{}}	\toprule
			
			& \multirow{3}{*}{\vspace*{4pt}\textbf{Method}}&\multicolumn{7}{c}{\textbf{Dataset}}\\\cmidrule{3-9}
			& & {\textsc{Enyzmes}}         &  {\textsc{Imdb-Binary}}      & {\textsc{Imdb-Multi}}           & {\textsc{NCI1}}       & {\textsc{Proteins}}           & {\textsc{Reddit-Binary}}   & {\textsc{deezer\_ego\_nets}}      \\	\toprule
			\multirow{4}{*}{\rotatebox{90}{Kernel}}	& \text{1-WL}            &  50.1  \scriptsize $\pm 1.6 \pm 6.2 $       & 72.4 \scriptsize $\pm  0.5 \pm 4.0$ & 50.1  \scriptsize $\pm 0.5 \pm  3.8 $ & 84.3 \scriptsize $\pm 0.3 \pm 1.6$ &73.0  \scriptsize $\pm 0.8 \pm  4.2 $ & 72.6 \scriptsize $\pm  0.4 \pm 3.1 $ & 56.4   \scriptsize $\pm  0.3 \pm 1.7$   \\
				& \text{WLOA}          & 56.8  \scriptsize $\pm  1.7\pm6.4 $       & 72.7  \scriptsize $\pm 0.7 \pm 4.3$ & 49.5 \scriptsize $\pm  0.4 \pm  3.5 $ & 84.9 \scriptsize $\pm  0.4 \pm 1.7$ &73.4  \scriptsize $\pm 0.7 \pm 3.7$ & 88.1 \scriptsize $\pm 0.3 \pm 2.5 $&  \scriptsize $\pm $    \\
				& \text{GR}            &  31.9   \scriptsize $\pm 1.1 \pm4.8$       & 59.4  \scriptsize $\pm 0.4 \pm 4.6$ & 39.3 \scriptsize $\pm 0.8 \pm  4.1 $ & 58.7  \scriptsize $\pm 0.4 \pm 2.3$ & 69.0  \scriptsize $\pm 0.8 \pm 4.3$ &60.0  \scriptsize $\pm 0.2 \pm 3.2 $&  \scriptsize $\pm $    \\
				& \text{SP}            &  40.6 \scriptsize $\pm  1.8\pm 5.8 $       & 58.3  \scriptsize $\pm 0.8 \pm  4.9$ & 39.0 \scriptsize $\pm 0.5 \pm  3.8$ &  74.1  \scriptsize $\pm 0.5 \pm 2.0 $  & 75.4  \scriptsize $\pm 0.5 \pm 4.1$ & 84.6 \scriptsize $\pm 0.3 \pm 2.5 $&   \scriptsize $\pm $   \\
			\cmidrule{2-9}	
			\multirow{2}{*}{\rotatebox{90}{GNN}}	& \text{GIN}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ &   \scriptsize $\pm $   \\
		& \text{Sage}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $   \\
			\bottomrule
	\end{tabular}}
\end{table*}		



\begin{table*}[t]\centering		
	\caption{Classification accuracies in percent and standard deviations,  \textsc{OOT}--- Computation did not finish within one day, \textsc{OOM}--- Out of memory.}
	\label{t2l}	
	\resizebox{0.6\textwidth}{!}{ 	\renewcommand{\arraystretch}{1.1}
		\begin{tabular}{@{}c <{\enspace}@{}lccccc@{}}	\toprule
			& \multirow{3}{*}{\vspace*{4pt}\textbf{Method}}&\multicolumn{5}{c}{\textbf{Dataset}}\\\cmidrule{3-7}
			& & {\textsc{Mcf-7}}         &  {\textsc{Molt-4}}      & {\textsc{Triangles}}           & {\textsc{github\_stargazers}}       & {\textsc{reddit\_threads}}      \\	\toprule
							\multirow{4}{*}{\rotatebox{90}{Kernel}}	& \text{1-WL}    & 94.23 
							   \scriptsize $\pm 0.11  \pm 0.49$       & 94.29 \scriptsize $\pm 0.07  \pm 0.39$ & \scriptsize $\pm \pm$ &  \scriptsize $\pm \pm$ & \scriptsize $\pm \pm$  \\
		
			& \text{GR}            &  91.71 \scriptsize $\pm  0.04   \pm 0.52 $       & 92.10  \scriptsize $\pm 0.02 \pm 0.45$ & \scriptsize $\pm \pm$ &  \scriptsize $\pm \pm$ & \scriptsize $\pm \pm$  \\  
			& \text{SP}             &   91.73 \scriptsize $\pm 0.03  \pm 0.49$       & 92.05 \scriptsize $\pm 0.02 \pm 0.44 $ & \scriptsize $\pm \pm$ &  \scriptsize $\pm \pm$ & \scriptsize $\pm \pm$  \\   
			\cmidrule{2-7}	
			\multirow{2}{*}{\rotatebox{90}{GNN}}	& \text{GIN}            &    \scriptsize $\pm  \pm $       & \scriptsize $\pm \pm $ & \scriptsize $\pm \pm$ &  \scriptsize $\pm \pm$ & \scriptsize $\pm \pm$ \\
			& \text{Sage}            &    \scriptsize $\pm \pm$       & \scriptsize $\pm \pm$ & \scriptsize $\pm \pm$ &  \scriptsize $\pm \pm$ & \scriptsize $\pm \pm $  \\
			\bottomrule
	\end{tabular}}
\end{table*}		




\begin{table}[t]\centering		
	\caption{Results for neural and kernel baselines.}
	\label{t2l}	
	\resizebox{0.55\columnwidth}{!}{ 	\renewcommand{\arraystretch}{1.1}
		\begin{tabular}{@{}c <{\enspace}@{}lcc@{}}	\toprule
			
			& \multirow{3}{*}{\vspace*{4pt}\textbf{Method}}&\multicolumn{2}{c}{\textbf{Dataset}}\\\cmidrule{3-4}
			&  & {\textsc{Zinc} (10k)}         &  {\textsc{Zinc} (50k)}         \\	
			\toprule
			\multirow{3}{*}{\rotatebox{90}{Kernel}}	& \text{1-WL}             &   &     \\
				& \text{GR}            &  &  \\  
			& \text{SP}             &  & \\   
			\cmidrule{2-4}
			\multirow{2}{*}{\rotatebox{90}{GNN}} & \text{$1$-GNN-E}             &  0.278 \scriptsize $\pm 0.022$  &	\\	
			& \text{$1$-GNN}             &  0.383 \scriptsize $\pm  0.020$    &  0.247 \scriptsize $\pm   0.020$ \\
			\bottomrule
	\end{tabular}}
\end{table}		



\section{Conclusion}

We gave an overview of the \textsc{Tud dataset}, and reported on the results of an experimental study comparing graph kernels and GNNs on a subset of the data. We believe that our dataset collection will spark further progress in the area of graph represention learning. We are looking forward to adding more dataset to our collection, and are excited about contributions from the community, and reseachers and practitionors from other areas.


\section{Acknowledgement}

We thank everybody who provided datasets for \textsc{Tud dataset}.

\bibliography{bibliography}
\bibliographystyle{icml2020}

\appendix


\end{document}

