%%%%%%%% ICML 2020 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}



\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage{booktabs}
\usepackage{url}
\usepackage{todonotes}
\usepackage{multirow}
\usepackage{tikz}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{thmtools}		
\usepackage{mleftright}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{remark}[theorem]{Remark}

\usepackage{thm-restate}
\usepackage[mathic=true]{mathtools}
\usepackage{fixmath}
\usepackage{siunitx}

\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{enumitem}
\setlist[enumerate]{noitemsep, topsep=0.5\topsep}
\setlist[description]{noitemsep, topsep=0.5\topsep}
\setlist[itemize]{noitemsep, topsep=0.5\topsep}

\usepackage{enumitem}
\setlist[enumerate]{noitemsep, topsep=0.5\topsep}
\setlist[description]{noitemsep, topsep=0.5\topsep}
\setlist[itemize]{noitemsep, topsep=0.5\topsep}

\usepackage{setspace}
\usepackage[protrusion=true,expansion=false, activate={true,nocompatibility},final,kerning=true,spacing=true]{microtype}

\usepackage{ellipsis}
\usepackage{xspace}
\usepackage{hfoldsty}

\usepackage{ifthen}
\newcommand{\CC}[1][]{$\text{C\hspace{-.25ex}}^{_{_{_{++}}}}
	\ifthenelse{\equal{#1}{}}{}{\text{\hspace{-.625ex}#1}}$}

\newcommand{\win}[1]{$\hspace{-0.3mm}$\textbf{#1}}
\newcommand{\sd}[1]{\scriptsize{$\pm$#1}}


% Let cleveref and thmtools work together
\makeatletter
\def\thmt@refnamewithcomma #1#2#3,#4,#5\@nil{%
	\@xa\def\csname\thmt@envname #1utorefname\endcsname{#3}%
	\ifcsname #2refname\endcsname
	\csname #2refname\expandafter\endcsname\expandafter{\thmt@envname}{#3}{#4}%
	\fi
}
\makeatother
\usepackage[capitalise,noabbrev]{cleveref}   

\newcommand{\new}[1]{\emph{#1}}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\newcommand{\cA}{\ensuremath{{\mathcal A}}\xspace}
\newcommand{\cB}{\ensuremath{{\mathcal B}}\xspace}
\newcommand{\cC}{\ensuremath{{\mathcal C}}\xspace}
\newcommand{\cD}{\ensuremath{{\mathcal D}}\xspace}
\newcommand{\cF}{\ensuremath{{\mathcal F}}\xspace}
\newcommand{\cH}{\ensuremath{{\mathcal H}}\xspace}
\newcommand{\cN}{\ensuremath{{\mathcal N}}\xspace}
\newcommand{\cO}{\ensuremath{{\mathcal O}}\xspace}
\newcommand{\cP}{\ensuremath{{\mathcal P}}\xspace}
\newcommand{\cR}{\ensuremath{{\mathcal R}}\xspace}
\newcommand{\cS}{\ensuremath{{\mathcal S}}\xspace}
\newcommand{\cU}{\ensuremath{{\mathcal U}}\xspace}
\newcommand{\cV}{\ensuremath{{\mathcal V}}\xspace}
\newcommand{\cPn}{\ensuremath{{\mathcal P}_n}\xspace}

\newcommand{\fA}{\ensuremath{\mathfrak{A}}\xspace}
\newcommand{\fB}{\ensuremath{\mathfrak{B}}\xspace}
\newcommand{\fC}{\ensuremath{\mathfrak{C}}\xspace}

\newcommand{\fa}{\ensuremath{\mathfrak{a}}\xspace}
\newcommand{\fb}{\ensuremath{\mathfrak{b}}\xspace}
\newcommand{\fc}{\ensuremath{\mathfrak{c}}\xspace}
\newcommand{\fd}{\ensuremath{\mathfrak{d}}\xspace}

\newcommand{\bA}{\ensuremath{{\bf A}}\xspace}
\newcommand{\bB}{\ensuremath{{\bf B}}\xspace}
\newcommand{\bK}{\ensuremath{{\bf K}}\xspace}
\newcommand{\bE}{\ensuremath{{\bf E}}\xspace}
\newcommand{\bN}{\ensuremath{{\bf N}}\xspace}
\newcommand{\bG}{\ensuremath{{\bf G}}\xspace}

\newcommand{\ba}{\ensuremath{{\bf a}}\xspace}
\newcommand{\bb}{\ensuremath{{\bf b}}\xspace}
\newcommand{\bc}{\ensuremath{{\bf c}}\xspace}

\newcommand{\bbE}{\ensuremath{\mathbb{E}}}
\newcommand{\bbR}{\ensuremath{\mathbb{R}}}
\newcommand{\bbQ}{\ensuremath{\mathbb{Q}}}
\newcommand{\bbP}{\ensuremath{\mathbb{P}}}
\newcommand{\bbZ}{\ensuremath{\mathbb{Z}}}
\newcommand{\bbN}{\ensuremath{\mathbb{N}}}
\newcommand{\bbNn}{\ensuremath{\mathbb{N}_0}}

\newcommand{\bbRnp}{\ensuremath{\bbR_{\geq 0}}}
\newcommand{\bbQnp}{\ensuremath{\bbQ_{\geq}}}
\newcommand{\bbZnp}{\ensuremath{\bbZ_{\geq}}}

\newcommand{\bbRsp}{\ensuremath{\bbR_>}}
\newcommand{\bbQsp}{\ensuremath{\bbQ_>}}
\newcommand{\bbZsp}{\ensuremath{\bbZ_>}}

\newcommand{\cp}{\textsf{P}\xspace}
\newcommand{\cnp}{\textsf{NP}\xspace}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\GG}{\mathbb{G}}
\newcommand{\GN}{\mathbb{G}_n}
\newcommand{\rb}{\right\}\xspace}
\newcommand{\lb}{\left\{\xspace}
\newcommand{\lbr}{\left(\xspace} 
\newcommand{\rbr}{\right)\xspace}
\newcommand{\ndelta}{\ensuremath{\overline{\delta}}}
\newcommand{\oms}{\{\!\!\{}
\newcommand{\cms}{\}\!\!\}}
\newcommand{\trans}{^T}
\renewcommand{\vec}[1]{\mathbf{#1}}

\usepackage{ifthen}
\newcommand{\CPP}[1][]{$\text{C\hspace{-.25ex}}^{_{_{_{++}}}}
	\ifthenelse{\equal{#1}{}}{}{\text{\hspace{-.625ex}#1}}$}

\usepackage{icml2020}





\icmltitlerunning{TUD Datasets}

\begin{document}

\twocolumn[
\icmltitle{TUD Datasets: A collection of benchmark datasets for learning with graphs}
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{C. Morris}{p}
\icmlauthor{N.\,M.\,Kriege}{vie}
\icmlauthor{K. Kersting}{darm}
\icmlauthor{P. Mutzw}{bonn}
\icmlauthor{N. Neumann}{wustl}
\end{icmlauthorlist}

\icmlaffiliation{p}{CERC in Data Science for Real-Time Decision-Making, Polytechnique Montr√©al}
\icmlaffiliation{vie}{University of Vienna}
\icmlaffiliation{darm}{Machine Learning Group, TU Darmstadt}
\icmlaffiliation{bonn}{Department of Computer Science, University of Bonn}
\icmlaffiliation{wustl}{Washington University in St. Louis}
\icmlcorrespondingauthor{Christopher Morris}{christopher.morris@tu-dortmund.de}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Recently, there has been an increasing interest in learning with graph data, especially using graph neural networks.  However, the development of meaningful benchmark datasets and standardized evaluation procedures is lagging behind. That is, most paper papers evaluate their methods on small-scale datasets leading to high standard deviations and hard to interpret results, consequently hindering advancements in this area. To address this, we introduce the \textsc{Tud dataset} for graph classification and regression. The dataset consists of over 150 datasets from a wide range of applications and varying sizes. We provide Python-based data loaders, baseline implementations, and evaluation tools. Here, we give an overview of the datasets, evaluation tools, and provide baseline experiments. 
\end{abstract}

\section{Introduction}

Graph-structured data is ubiquitous across application domains ranging from chemo- and bioinformatics to image and social network analysis. To develop successful machine learning models in these domains, we need techniques that can exploit the rich information inherent in the graph structure, as well as the feature information contained within nodes and edges. In recent years, numerous approaches have been proposed for machine learning with graphs---most notably, approaches based on graph \new{kernels}~\cite{Kri+2019} or using \new{graph neural networks} (GNNs)~\cite{Gil+2017}. However, most papers, even recent ones, evaluate newly proposed architectures or methods on a fixed set of small-scale benchmark datasets leading to high standard deviations and hard to interpret results. 

Here, we give an overview of \textsc{Tud datasets}. The benchmark collection consists of over 150 datasets from a wide range of domains for supervised learning with graphs, i.e., classificiation and regression. All datasets are provided in a common dataset format at \url{graphlearning.io}, and easily be accessed from popular graph learning frameworks such as \emph{Pytorch Geometric}~\cite{Fey+2019} and \emph{DGL}~\cite{Wan+2019}.

\paragraph{Related work.}

There exists two approaches to supervised learing with graphs, graph kernels and graph neural networks (GNNs). Graph kernels have been studied extensively in the past 15 years, see ~\cite{Kri+2019} for a thorough overview. 
Important approaches include random-walk and shortest paths based kernels~\cite{Gaertner2003,Sugiyama2015,Bor+2005,Kri+2017b}, as well as the Weisfeiler-Lehman subtree kernel~\cite{She+2011,Mor+2017}. 
Further recent works focus on assignment-based approaches~\cite{Kri+2016,Nik+2017}, spectral approaches~\cite{Kon+2016}, and graph decomposition approaches~\cite{Nik+2018}.

Recently, GNNs~\cite{Gil+2017} emerged as a alternative to graph kernels. Notable instances of this model include~\cite{Duv+2015},~\cite{Li+2016},~\cite{Ham+2017} and the spectral approaches proposed in~\cite{Bru+2014,Def+2015,Kip+2017}---all of which descend from early work in~\cite{Kir+1995,Mer+2005,Sca+2009}. A unifying message passing architecture can be found in~\cite{Gil+2017}. Two recent surveys~\cite{wu2019comprehensive,zhou2018graph} provide a thorough overview of graph neural networks

The papers~\cite{Fey+2019,Err+2019,Dwi+2020} evalute GNNs using a unified evaluation procedure, however, both only use small scale datasets. Recently, \url{ogb.stanford.edu} launchend, however the provided datasets for graph classification focus on chemistry applications, and the number is quite limited at this point.



\paragraph{Contributions} We give an overview of \textsc{Tud dataset}, its unified evalution procudures, and baseline methods. Moreover, we report results on a experimental study comparing graph kernels and GNNs on a subset of the \textsc{Tud dataset}.

\section{Overview of the datasets}

The \textsc{Tud dataset} contain over 150 datasets provided at \url{graphlearning.io}. The data loader, baseline methods, experimental evaluation tool can be installed by running \texttt{pip install tud-datasets}, see \url{XXX} for further details.

\subsection{Baselines}

In order to provide meaningful baselines, we provide implementation of common graph kernels was well as GNNs baselines. We have implemented the \new{Weisfeiler-Lehman Subtree}~\cite{Shervashidze2011}, \new{Shortest-path}~\cite{Bor+2005}, \new{Graphket}~\cite{She+2009}, \new{Weisfeiler-Lehman Optimal Assigment}~\cite{Kri+2016} kernel, as well as the higher-order WL kernels~\cite{Mor+2019b}, in \CPP and made them accessable through the Python interface of \textsc{Tud dataset}, see \url{XXX} for further details.  Moreover, all GNN architectures implemented in PyTorch Geometric can be used as baseline as well. 

Vertex kernel and edge kernel?


\subsection{Evaluation tools}\label{eval}

In order to insure a fair and meaningful comparision between methods, we propose the following evaluation proceudres, and software tools for kernels and GNN approaches. All proposed methods can be conviently accessed from the Python interface, see \url{XXX} for further details. First, for kernels we propose the established $C$-SVM implementation \textsc{LibSvm}~\cite{Cha+11} for kernels that compute a Gram matrix, and the linear $C$-SVM implementation \textsc{LibLinear}~\cite{Fan+2008} for kernels  that can be computed based on explicit feature maps. We optimize GNNs end-to-end using \textsc{Adam}~\cite{}. Too compute accuracies and other metrics for evaluation, we propose to use $10$-fold cross validation, where we select a validation set uniformly at random from each training fold ($10\%$ of the training fold), to select hyperparamets, e.g., number of iterations, $C$ parameter, number of layers, learning rate, feature dimension, etc.  


Repeat ten times?



\section{Experimental evaluation}

Our intention here is to provide baseline experiments, and compare graph kernels and GNNs. More precisely, we address the following questions:
\begin{description}
	\item[Q1] Are GNNs superior to graph kernels? Is there a single method that dominates?
	\item[Q2] ?
	\item[Q3] ?
\end{description}

\subsection{Experimental protocol}

We used the following datasets, graph kernels, and GNN baselines.

\paragraph{Datasets.} We used the \textsc{deezer\_ego\_nets}, \textsc{github\_stargazers}, \textsc{Enymes},
\textsc{Imdb-BINARY}, \textsc{Imdb-MULTI}, \textsc{Mcf-7}, \textsc{Molt-4},	\textsc{Nci1}, \textsc{Proteins},
\textsc{Reddit-Binary},	\textsc{reddit\_threads}, \textsc{twitch\_egos}, \textsc{Uacc257}. See the appendix for dataset statistics.

\paragraph{Graph kernels.} As kernel baselines we used the \new{Weisfeiler-Lehman Subtree}~\cite{Shervashidze2011}, \new{Shortest-path}~\cite{Bor+2005}, \new{Graphket}~\cite{She+2009}, \new{Weisfeiler-Lehman Optimal Assigment} \textsc{WL-OA}~\cite{Kri+2016}, and $\delta$-$2$-LWL$^+$ kernel~\cite{Mor+2019b} included in the \textsc{TUD Dataset} package. The $C$-parameter was selected from $\{10^{-3}, 10^{-2}, \dotsc, 10^{2},$ $10^{3}\}$ from the validation set. For the larger datasets, we computed sparse feature vectors for each graph and used the linear $C$-SVM implementation of \text{Liblinear}~\cite{Fan+2008}. The number of iterations of the \textsc{$1$-WL}, \textsc{WL-OA}, and the  $\delta$-$2$-LWL$^+$ were selected from $\{0,\dotsc,5\}$.\footnote{As already shown in~\cite{She+2011}, choosing the number of iterations too large will lead to overfitting.}

\paragraph{GNNs.} We used the GNN architectures \textsc{GCN}~\cite{Kip+2017}, \textsc{Sage}~\cite{Ham+2017}, \textsc{Gin} and \textsc{Gin-$\varepsilon$}~\cite{Xu+2018b} as neural baselines. For all experiments, we used the global mean operator to obtain graph-level outputs. For each dataset, we optimize the number of hidden units from $
\{16, 32, 64, 128\}$, the number of layers from $ \{2, 3, 4, 5\}$ and the learning rate from $ \{0.0001, 0.001, 0.01 \}$ with respect to the validation set. The batch size was fixed to $128$.

For both methods, we used the evaluation procecude described in~\cref{eval} to optimize hyperparameters and compute accuracies. All experiments can be fulled reprodcued from the scripts provided at \url{XXX}.

\subsection{Results and discussion}
See~\cref{t2l}.


\begin{table*}[t]\centering		
	\caption{Classification accuracies in percent and standard deviations,  \textsc{OOT}--- Computation did not finish within one day, \textsc{OOM}--- Out of memory.}
	\label{t2l}	
	\resizebox{0.6\textwidth}{!}{ 	\renewcommand{\arraystretch}{1.1}
		\begin{tabular}{@{}c <{\enspace}@{}lcccccc@{}}	\toprule
			
			& \multirow{3}{*}{\vspace*{4pt}\textbf{Graph Kernel}}&\multicolumn{6}{c}{\textbf{Dataset}}\\\cmidrule{3-8}
			& & {\textsc{Data0}}         &  {\textsc{Data1}}      & {\textsc{Data1}}           & {\textsc{Data1}}       & {\textsc{Data1}}           & {\textsc{Data1}}      \\	\toprule
			\multirow{4}{*}{\rotatebox{90}{Kernel}}	& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
				& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
				& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
				& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
			\cmidrule{2-8}	
			\multirow{4}{*}{\rotatebox{90}{GNN}}	& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
		& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
		& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
		& \text{1-WL}            &    \scriptsize $\pm $       & \scriptsize $\pm $ & \scriptsize $\pm $ &  \scriptsize $\pm $ & \scriptsize $\pm $ & \scriptsize $\pm $ \\
			\bottomrule
	\end{tabular}}
\end{table*}		


\section{Conclusion}

We gave an overview of the \textsc{Tud dataset}, and reported on the results of an experimental study comparing graph kernels and GNNs on a subset of the data. We believe that our dataset collection will spark further progress in the area of graph represention learning. We are looking forward to adding more dataset to our collection, and are excited about contributions from the community, and reseachers and practitionors from other areas.


\section{Acknowledgement}

We thank everybody who provided datasets for \textsc{Tud dataset}.

\bibliography{bibliography}
\bibliographystyle{icml2020}

\appendix


\end{document}

